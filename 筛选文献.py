import streamlit as st
import os
import pypdf
from typing import TypedDict, List
from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# ==========================================
# 1. åŸºç¡€é…ç½®ä¸å·¥å…·å‡½æ•°
# ==========================================
st.set_page_config(page_title="è¯å­¦æ–‡çŒ®æ™ºèƒ½ç­›é€‰å¹³å°", layout="wide", page_icon="ğŸ’Š")

def extract_text_from_pdf(uploaded_file):
    """è¾…åŠ©å‡½æ•°ï¼šå°†ä¸Šä¼ çš„PDFæ–‡ä»¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ–‡æœ¬"""
    try:
        pdf_reader = pypdf.PdfReader(uploaded_file)
        text = ""
        # ä¸ºäº†é˜²æ­¢Tokenæº¢å‡ºï¼Œè¿™é‡Œå¯ä»¥é™åˆ¶è¯»å–å‰Né¡µï¼Œæˆ–è€…è¯»å–å…¨éƒ¨
        # è¿™é‡Œé»˜è®¤è¯»å–å…¨éƒ¨ï¼ŒDeepSeekçª—å£å¾ˆå¤§ï¼Œé€šå¸¸èƒ½è¿™å°±holdä½
        for page in pdf_reader.pages:
            content = page.extract_text()
            if content:
                text += content + "\n"
        return text
    except Exception as e:
        return f"Error reading PDF: {e}"

# ==========================================
# 2. å®šä¹‰ Agent çŠ¶æ€ (State)
# ==========================================
class LiteratureState(TypedDict):
    file_name: str          # æ–‡ä»¶å
    raw_content: str        # PDF æå–å‡ºçš„åŸæ–‡
    screening_criteria: str # ç”¨æˆ·è®¾å®šçš„ç­›é€‰æ ‡å‡†ï¼ˆå˜é‡ï¼‰
    extracted_data: str     # ç­›é€‰å‡ºçš„æ•°æ®
    quality_report: str     # ç›‘æ§è€…çš„è¯„åˆ†æŠ¥å‘Š

# ==========================================
# 3. æ ¸å¿ƒå¤„ç†é€»è¾‘ (å°è£…ä¾› Streamlit è°ƒç”¨)
# ==========================================
def process_document(api_key, model_name, file_obj, criteria):
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["DEEPSEEK_API_KEY"] = api_key
    
    # åˆå§‹åŒ–æ¨¡å‹
    # æ³¨æ„ï¼šDeepSeek çš„æ¨ç†æ¨¡å‹é€šå¸¸å« deepseek-reasonerï¼Œé€šç”¨æ¨¡å‹å« deepseek-chat
    llm = ChatOpenAI(
        model=model_name, 
        openai_api_key=api_key,
        openai_api_base="https://api.deepseek.com",
        temperature=0  # ç§‘ç ”æ•°æ®è¦æ±‚ä¸¥è°¨
    )

    # --- èŠ‚ç‚¹ 1: æŠ“å–ä¸é¢„å¤„ç†æ™ºèƒ½ä½“ ---
    # è´Ÿè´£å°† PDF å¯¹è±¡è½¬åŒ–ä¸º LLM å¯è¯»çš„æ–‡æœ¬
    def pdf_loader_agent(state: LiteratureState):
        # è¿™ä¸€æ­¥å…¶å®åœ¨ä¼ å…¥å‰å·²ç»ç”±å·¥å…·å‡½æ•°è¾…åŠ©å®Œæˆäº†ï¼Œ
        # ä½†åœ¨é€»è¾‘ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œåšè¿›ä¸€æ­¥çš„æ•°æ®æ¸…æ´—ï¼ˆå¦‚å»æ‰é¡µçœ‰é¡µè„šï¼‰
        text = state["raw_content"]
        # ç®€å•æ¸…æ´—ï¼šå»æ‰è¿‡å¤šçš„ç©ºè¡Œ
        clean_text = "\n".join([line for line in text.split('\n') if line.strip()])
        return {"raw_content": clean_text}

    # --- èŠ‚ç‚¹ 2: ç­›é€‰åˆ†ææ™ºèƒ½ä½“ ---
    # æ ¹æ®ç”¨æˆ·åŠ¨æ€è®¾å®šçš„ criteria è¿›è¡Œæå–
    def filter_agent(state: LiteratureState):
        prompt = f"""
        ä½ æ˜¯ä¸€åä¸“ä¸šçš„è¯å­¦æ•°æ®åˆ†æå¸ˆã€‚
        ä»»åŠ¡ï¼šè¯·æ ¹æ®ä»¥ä¸‹ã€ç­›é€‰æ ‡å‡†ã€‘ï¼Œä»ã€æ–‡çŒ®å†…å®¹ã€‘ä¸­æå–ç²¾ç¡®çš„æ•°æ®ã€‚
        
        ã€ç­›é€‰æ ‡å‡†ã€‘: 
        {state["screening_criteria"]}
        
        ã€æ–‡çŒ®å†…å®¹ã€‘(éƒ¨åˆ†å±•ç¤º):
        {state["raw_content"][:30000]} ... (å†…å®¹è¿‡é•¿å·²æˆªæ–­ï¼Œè¯·åŸºäºå…¨é‡ç†è§£)
        
        è¦æ±‚ï¼š
        1. åªè¾“å‡ºæå–åˆ°çš„æ•°æ®ç»“æœï¼Œå¯ä»¥æ˜¯è¡¨æ ¼å½¢å¼æˆ–åˆ—è¡¨å½¢å¼ã€‚
        2. å¦‚æœæ–‡ä¸­æœªæåŠæŸé¡¹æ ‡å‡†ï¼Œè¯·æ˜ç¡®æ ‡æ³¨â€œæœªæ‰¾åˆ°â€ã€‚
        3. ä¸è¦è¾“å‡ºæ— å…³çš„å¯’æš„è¯­ã€‚
        """
        # æ³¨æ„ï¼šå®é™…å‘é€æ—¶å»ºè®®å‘é€å®Œæ•´ contentï¼Œè¿™é‡Œä¸ºäº†æ¼”ç¤º Prompt ç»“æ„
        # çœŸå®è°ƒç”¨ä½¿ç”¨å®Œæ•´æ–‡æœ¬
        real_msg = prompt.replace(f"{state['raw_content'][:30000]} ... (å†…å®¹è¿‡é•¿å·²æˆªæ–­ï¼Œè¯·åŸºäºå…¨é‡ç†è§£)", state["raw_content"])
        
        response = llm.invoke([HumanMessage(content=real_msg)])
        return {"extracted_data": response.content}

    # --- èŠ‚ç‚¹ 3: ç›‘ç£ç›‘æ§æ™ºèƒ½ä½“ (Thinker) ---
    # è´Ÿè´£æ£€æŸ¥å‡†ç¡®ç‡ï¼ŒDeepSeek-R1 (Reasoner) åœ¨æ­¤ç±»åæ€ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚
    def monitor_agent(state: LiteratureState):
        prompt = f"""
        ä½ æ˜¯ä¸€åä¸¥æ ¼çš„ç§‘ç ”è´¨é‡ç›‘ç£å‘˜ã€‚
        
        ä½ çš„ä»»åŠ¡æ˜¯å®¡æ ¸ä¸Šä¸€æ­¥çš„ã€æå–ç»“æœã€‘æ˜¯å¦å¿ å®äºã€æ–‡çŒ®åŸæ–‡ã€‘ä»¥åŠæ˜¯å¦ç¬¦åˆã€ç­›é€‰æ ‡å‡†ã€‘ã€‚
        
        ã€ç”¨æˆ·æ ‡å‡†ã€‘: {state["screening_criteria"]}
        ã€æå–ç»“æœã€‘: {state["extracted_data"]}
        ã€æ–‡çŒ®åŸæ–‡ç‰‡æ®µã€‘: {state["raw_content"][:5000]}...
        
        è¯·è¾“å‡ºä¸€ä»½ç®€çŸ­çš„ã€è´¨é‡ç›‘æ§æŠ¥å‘Šã€‘ï¼š
        1. å‡†ç¡®ç‡è¯„åˆ† (0-100)ã€‚
        2. æ˜¯å¦å­˜åœ¨å¹»è§‰æˆ–é—æ¼ï¼Ÿ
        3. æœ€ç»ˆä¿®æ­£å»ºè®®ï¼ˆå¦‚æœ‰ï¼‰ã€‚
        """
        response = llm.invoke([HumanMessage(content=prompt)])
        return {"quality_report": response.content}

    # --- æ„å»ºå›¾ ---
    workflow = StateGraph(LiteratureState)
    
    workflow.add_node("PDF_Loader", pdf_loader_agent)
    workflow.add_node("Filter", filter_agent)
    workflow.add_node("Monitor", monitor_agent)
    
    workflow.add_edge(START, "PDF_Loader")
    workflow.add_edge("PDF_Loader", "Filter")
    workflow.add_edge("Filter", "Monitor")
    workflow.add_edge("Monitor", END)
    
    app = workflow.compile()
    
    # é¢„å…ˆè¯»å– PDF æ–‡æœ¬
    raw_text = extract_text_from_pdf(file_obj)
    
    # å¯åŠ¨å·¥ä½œæµ
    inputs = {
        "file_name": file_obj.name,
        "raw_content": raw_text,
        "screening_criteria": criteria,
        "extracted_data": "",
        "quality_report": ""
    }
    
    return app.invoke(inputs)

# ==========================================
# 4. Streamlit ç•Œé¢æ„å»º
# ==========================================

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ å…¨å±€è®¾ç½®")
    api_key = st.text_input("DeepSeek API Key", type="password")
    
    # è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹ï¼šå¦‚æœä½ çš„è´¦å·æ”¯æŒæ¨ç†æ¨¡å‹ï¼Œé€‰ reasoner æ•ˆæœæ›´å¥½
    model_choice = st.selectbox(
        "é€‰æ‹©æ¨¡å‹èƒ½åŠ›", 
        ("deepseek-chat (å¿«é€Ÿ)", "deepseek-reasoner (æ·±åº¦æ€è€ƒ)")
    )
    # æ˜ å°„åˆ°çœŸå®çš„ API model name
    model_map = {
        "deepseek-chat (å¿«é€Ÿ)": "deepseek-chat",
        "deepseek-reasoner (æ·±åº¦æ€è€ƒ)": "deepseek-reasoner"
    }
    selected_model = model_map[model_choice]

    st.markdown("---")
    st.info("ğŸ’¡ **æç¤º**: \nDeepSeek-V3 (chat) é€‚åˆå¿«é€Ÿæå–ã€‚\nDeepSeek-R1 (reasoner) é€‚åˆå¤æ‚çš„é€»è¾‘æ ¡éªŒã€‚")

st.title("ğŸ’Š è¯å­¦æ–‡çŒ®æ‰¹é‡æ™ºèƒ½ç­›é€‰ç³»ç»Ÿ")
st.markdown("---")

# 1. å˜é‡è®¾ç½®åŒº (ç”¨æˆ·éœ€æ±‚çš„æ ¸å¿ƒ)
st.subheader("1. è®¾å®šç­›é€‰æ ‡å‡† (å˜é‡å®šä¹‰)")
default_criteria = """
è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼š
1. è¯ç‰©åç§° (Drug Name)
2. å®éªŒç»„æ ·æœ¬é‡ (Sample Size)
3. æ ¸å¿ƒä¸è‰¯ååº” (Adverse Events)
4. På€¼ (P-value)
"""
criteria_input = st.text_area("åœ¨æ­¤å®šä¹‰ä½ æƒ³ä»æ–‡çŒ®ä¸­æŒ–æ˜ä»€ä¹ˆæ•°æ®ï¼š", value=default_criteria, height=150)

# 2. æ–‡ä»¶ä¸Šä¼ åŒº
st.subheader("2. ä¸Šä¼ æ–‡çŒ® (æ”¯æŒæ‰¹é‡)")
uploaded_files = st.file_uploader("è¯·ä¸Šä¼  PDF æ–‡ä»¶", type=["pdf"], accept_multiple_files=True)

# 3. æ‰§è¡ŒæŒ‰é’®
if st.button("ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ", type="primary"):
    if not api_key:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ API Keyï¼")
    elif not uploaded_files:
        st.warning("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ª PDF æ–‡ä»¶ã€‚")
    else:
        # åˆ›å»ºä¸€ä¸ªè¿›åº¦æ¡
        progress_bar = st.progress(0)
        total_files = len(uploaded_files)
        
        st.markdown("### ğŸ“Š åˆ†æç»“æœçœ‹æ¿")
        
        # å¾ªç¯å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for idx, pdf_file in enumerate(uploaded_files):
            with st.expander(f"ğŸ“„ æ–‡ä»¶: {pdf_file.name}", expanded=True):
                with st.spinner(f"æ­£åœ¨è¯»å–å¹¶åˆ†æ {pdf_file.name} ..."):
                    try:
                        # è°ƒç”¨ Agent ç³»ç»Ÿ
                        result = process_document(api_key, selected_model, pdf_file, criteria_input)
                        
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.subheader("ğŸ” æ•°æ®æå–ç»“æœ")
                            st.markdown(result["extracted_data"])
                            
                        with col2:
                            st.subheader("ğŸ›¡ï¸ ç›‘ç£è€…æŠ¥å‘Š")
                            #ä»¥æ­¤ä¸åŒé¢œè‰²æ˜¾ç¤ºï¼Œå¢å¼ºè­¦ç¤ºä½œç”¨
                            st.info(result["quality_report"])
                            
                    except Exception as e:
                        st.error(f"å¤„ç†å¤±è´¥: {e}")
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.progress((idx + 1) / total_files)
            
        st.success("âœ… æ‰€æœ‰æ–‡çŒ®å¤„ç†å®Œæ¯•ï¼")    